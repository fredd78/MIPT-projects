{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Эксперименты с моделью\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Начнем с простого. Давайте оценим как много объектов действительно нужно для построения качественной модели. Для обучения доступна достаточно большая выборка и может так оказаться, что начиная с некоторого момента рост размера обучающей выборки перестает влиять на качество модели. Постройте кривые обучения, обучая модель на выборках разного размера начиная с небольшого количество объектов в обучающей выборке и постепенно наращивая её размер с некоторым шагом. Обратите внимание на `sklearn.model_selection.learning_curve`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка данных, выделение числовых и категориальных признаков, удаление пустых признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('orange_small_churn_train_data.csv', index_col = 0)\n",
    "num = np.array(train.columns[:190])\n",
    "cat = np.array(train.columns[190:230])\n",
    "num_cols = np.array(num[np.array(pd.notnull(train[num]).any())])\n",
    "cat_cols = np.array(cat[np.array(pd.notnull(train[cat]).any())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оставим категориальные признаки с менее чем 100 значениями, чтобы разреженная матрица не получилась слишком огромной"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = []\n",
    "for i in cat_cols:\n",
    "    if len(train[i].unique()) <= 100:\n",
    "        cats.append(i)\n",
    "cats = np.array(cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# У последнего объекта пропущено значение целевого признака\n",
    "train_num = train[num_cols][:-1]\n",
    "train_cat = train[cats][:-1]\n",
    "y_train = train['labels'][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0    16921\n",
       " 1.0     1377\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполнение пропущенных значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_num = train_num.fillna(0)\n",
    "train_cat = train_cat.fillna('NaN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кодирование категориальных данных с помощью DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "d = DictVectorizer(sparse = False)\n",
    "train_cat = pd.DataFrame(d.fit_transform(train_cat.T.to_dict().values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([train_num, train_cat], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбиение обучающей выборки на 3 фолда"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим кривые обучения модели градиентного бустинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "train_sizes_abs, train_scores, test_scores = learning_curve(\n",
    "    GradientBoostingClassifier(), X_train, y_train, \n",
    "               cv = skf, scoring = 'roc_auc', n_jobs = -1)\n",
    "train_scores_mean = np.mean(train_scores, axis = 1)\n",
    "test_scores_mean = np.mean(test_scores, axis = 1)\n",
    "plt.figure()\n",
    "plt.xlabel('Число объектов')\n",
    "plt.ylabel('Score')\n",
    "plt.grid()\n",
    "plt.plot(train_sizes_abs, train_scores_mean, 'o-', color = 'b', label = 'Score на тренировочной выборке')\n",
    "plt.plot(train_sizes_abs, test_scores_mean, 'o-', color = 'g', label = 'Score на кросс-валидации')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С увеличением числа объектов тренировочной выборки увеличивается качество на кросс-валидации - необходимо использовать всю выборку."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Часто несбалансированные по классам выборки приводят к различным проблемам при обучении моделей. Давайте попробуем по-разному обработать выборку, поиграть с распределением объектов по классам и сделать выводы о том, как соотношение классов влияет на качество модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1\\. Задайте веса объектам так, чтобы соотношение классов с учетом весов объектов изменилось. Попробуйте не менее трёх различных вариантов весов. Меняются ли результаты классификации? Как это сказывается на качестве модели? Какой вариант выглядит наиболее оптимальным с точки зрения качества?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим качество модели без весов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее качество без весов = 0.7195810759015654\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(GradientBoostingClassifier(), X_train, \n",
    "                y_train, scoring = 'roc_auc', cv = skf, n_jobs = -1)\n",
    "print('Среднее качество без весов =', scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Варианты весов: 1:5, 1:8, 1:10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее качество = 0.7232713061383661\n",
      "Среднее качество = 0.7238218726807273\n",
      "Среднее качество = 0.7215414566506416\n"
     ]
    }
   ],
   "source": [
    "sample_weight1 = np.array([1 if x == -1 else 5 for x in y_train])\n",
    "sample_weight2 = np.array([1 if x == -1 else 8 for x in y_train])\n",
    "sample_weight3 = np.array([1 if x == -1 else 10 for x in y_train])\n",
    "for sample_weight in sample_weight1, sample_weight2, sample_weight3:\n",
    "    scores = cross_val_score(GradientBoostingClassifier(), X_train, y_train, \n",
    "            scoring = 'roc_auc', cv = skf, fit_params = {'sample_weight': sample_weight}, n_jobs = -1)\n",
    "    print('Среднее качество =', scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшее качество показали веса **1:8**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2\\. Примените к выборке технологию undersampling: для этого нужно убрать из обучения некоторое количество объектов большего класса таким образом, чтобы соотношение классов изменилось. Попробуйте не менее трёх различных вариантов undersampling (варианты могут отличаться как по количество отфильтрованных объектов, так и по принципу выборка объектов для отсеивания из выборки). Меняются ли результаты классификации? Как это сказывается на качестве модели? Какой вариант выглядит наиболее оптимальным с точки зрения качества?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Отношение классов = 6.478576615831518:1, среднее качество = 0.7215702268975649\n",
      "Отношение классов = 5.026143790849673:1, среднее качество = 0.7230493282576882\n",
      "Отношение классов = 3.5737109658678285:1, среднее качество = 0.7140469735332268\n"
     ]
    }
   ],
   "source": [
    "for size in [8000, 10000, 12000]:\n",
    "    ind = y_train[y_train == -1].sample(size).index\n",
    "    scores = cross_val_score(GradientBoostingClassifier(), X_train.drop(ind), y_train.drop(ind),\n",
    "                             scoring = 'roc_auc', cv = skf, n_jobs = -1)\n",
    "    print(f'Отношение классов = {(16921 - size)/ 1377}:1, среднее качество = {scores.mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшее качество достигнуто при удалении 10000 объектов класса '-1' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Теперь перейдем к работе с признаками. Ранее вы реализовали несколько стратегий для обработки пропущенных значений. Сравните эти стратегии между собой с помощью оценки качества моделей кросс-валидации, построенных на датасетах с использованием различных стратегий. Как обработка пропущенных значений сказывается на качестве модели? Какой вариант выглядит наиболее оптимальным с точки зрения качества?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "При заполнении пропущенных числовых значений нулями среднее качество равно 0.7195810759015654.  \n",
    "Заполним пропущенные числовые значения средними по столбцам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество при заполнение средними = 0.72778986693576\n"
     ]
    }
   ],
   "source": [
    "train_num = train[num_cols][:-1].fillna(train[num_cols].mean())\n",
    "X_train_means = pd.concat([train_num, train_cat], axis = 1)\n",
    "scores = cross_val_score(GradientBoostingClassifier(), X_train_means,\n",
    "                         y_train, scoring = 'roc_auc', cv = skf, n_jobs = -1)\n",
    "print ('Качество при заполнение средними =', scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь заполним числовые значения медианами по столбцам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество при заполнение медианами = 0.722524579842247\n"
     ]
    }
   ],
   "source": [
    "train_num = train[num_cols][:-1].fillna(train[num_cols].median())\n",
    "X_train_medians = pd.concat([train_num, train_cat], axis = 1)\n",
    "scores = cross_val_score(GradientBoostingClassifier(), X_train_medians,\n",
    "                         y_train, scoring = 'roc_auc', cv = skf, n_jobs = -1)\n",
    "print ('Качество при заполнение медианами =', scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполнение средними даёт лучшее качество. Заменим X_train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. Также вы уже реализовали несколько стратегий для обработки категориальных признаков. Сравните эти стратегии между собой с помощью оценки качества моделей по кросс-валидации, построенных на датасетах с использованием различных стратегий. Как обработка категориальных признаков сказывается на качестве модели? Какой вариант выглядит наиболее оптимальным с точки зрения качества?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Кодирование категориальных данных было осуществлено с помощью DictVectorizer (метод One Hot Encoding).  \n",
    "Теперь используем метод label encoding - кодирование каждой категории уникальным целым числом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество при кодировании методом \"label encoding\" = 0.7265973029585487\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "l = LabelEncoder()\n",
    "train_cat = train[cat_cols][:-1]\n",
    "train_cat = train_cat.fillna('NaN')\n",
    "# Заполним средними числовые признаки\n",
    "train_num = train[num_cols][:-1].fillna(train[num_cols].mean())\n",
    "\n",
    "for i in cat_cols:\n",
    "    train_cat[i] = l.fit_transform(train_cat[i])\n",
    "X_train_l = pd.concat([train_num, train_cat], axis = 1)\n",
    "scores = cross_val_score(GradientBoostingClassifier(), X_train_l,\n",
    "                y_train, scoring = 'roc_auc', cv = skf, n_jobs = -1)\n",
    "print('Качество при кодировании методом \"label encoding\" =', scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем метод кодирования частотами значений признака в каждом столбце:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество при кодировании частотами = 0.7324317649877933\n"
     ]
    }
   ],
   "source": [
    "train_cat = train[cat_cols][:-1]\n",
    "train_cat = train_cat.fillna('NaN')\n",
    "for i in cat_cols:\n",
    "    freq = train_cat[i].value_counts()\n",
    "    train_cat[i] = np.array([freq[x] for x in train_cat[i]])\n",
    "X_train_f = pd.concat([train_num, train_cat], axis = 1)\n",
    "scores = cross_val_score(GradientBoostingClassifier(), X_train_f,\n",
    "                y_train, scoring = 'roc_auc', cv = skf, n_jobs = -1)\n",
    "print('Качество при кодировании частотами =', scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кодирование категориальных признаков частотами даёт лучшее качество. Заменим X_train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. Все ли признаки оказались полезными для построения моделей? Проведите процедуру отбора признаков, попробуйте разные варианты отбора (обратите внимание на модуль `sklearn.feature_selection`). Например, можно выбрасывать случайные признаки или строить отбор на основе l1-регуляризации - отфильтровать из обучения признаки, которые получат нулевой вес при построении регрессии с l1-регуляризацией (`sklearn.linear_model.Lasso`). И всегда можно придумать что-то своё=) Попробуйте как минимум 2 различные стратегии, сравните результаты. Помог ли отбор признаков улучшить качество модели? Поясните свой ответ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удаление признаков с нулевой дисперсией:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "X_train_1 = VarianceThreshold().fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество при использовании l1-регуляризации = 0.6853795803593621\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "lasso = Lasso(max_iter = 10000).fit(X_train_1, y_train)\n",
    "non_zero_w = np.flatnonzero(lasso.coef_)\n",
    "X_train_l1 = X_train_1.take(non_zero_w, axis = 1)\n",
    "scores = cross_val_score(GradientBoostingClassifier(), X_train_l1,\n",
    "                y_train, scoring = 'roc_auc', cv = skf, n_jobs = -1)\n",
    "print('Качество при использовании l1-регуляризации =', scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество при l1-регуляризации намного ниже. Используем **ANOVA F-value** для отбора лучших признаков: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество при отборе 40 лучших признаков = 0.736151744558803\n",
      "Качество при отборе 50 лучших признаков = 0.7373003853630617\n",
      "Качество при отборе 60 лучших признаков = 0.7373210106209843\n",
      "Качество при отборе 70 лучших признаков = 0.7359117821422491\n",
      "Качество при отборе 80 лучших признаков = 0.7359671208078273\n",
      "Качество при отборе 90 лучших признаков = 0.7338750444506603\n",
      "Качество при отборе 100 лучших признаков = 0.7344092784600345\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "for i in [40, 50, 60, 70, 80, 90, 100]:\n",
    "    X_f_classif = SelectKBest(k = i).fit_transform(X_train_1, y_train)\n",
    "    scores = cross_val_score(GradientBoostingClassifier(),\n",
    "    X_f_classif, y_train, scoring = 'roc_auc', cv = skf, n_jobs = -1)\n",
    "    print(f'Качество при отборе {i} лучших признаков =', scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшее качество достигается при отборе от 50 до 70 лучших признаков. Найдём подбором число признаков, для которого качество максимально:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Число признаков: 50, AUC-ROC = 0.7376623508171116\n",
      "Число признаков: 51, AUC-ROC = 0.7374395181677488\n",
      "Число признаков: 52, AUC-ROC = 0.7384928253719693\n",
      "Число признаков: 53, AUC-ROC = 0.7373239791950663\n",
      "Число признаков: 54, AUC-ROC = 0.7369608806898942\n",
      "Число признаков: 55, AUC-ROC = 0.7368623012362727\n",
      "Число признаков: 56, AUC-ROC = 0.7361855748263976\n",
      "Число признаков: 57, AUC-ROC = 0.7367738699613006\n",
      "Число признаков: 58, AUC-ROC = 0.7375763369468885\n",
      "Число признаков: 59, AUC-ROC = 0.7378410857883333\n",
      "Число признаков: 60, AUC-ROC = 0.7362340215185256\n",
      "Число признаков: 61, AUC-ROC = 0.7359609693686605\n",
      "Число признаков: 62, AUC-ROC = 0.7357482117290283\n",
      "Число признаков: 63, AUC-ROC = 0.7360456906450511\n",
      "Число признаков: 64, AUC-ROC = 0.735064096342598\n",
      "Число признаков: 65, AUC-ROC = 0.7348342539259288\n",
      "Число признаков: 66, AUC-ROC = 0.7346299396439759\n",
      "Число признаков: 67, AUC-ROC = 0.7343313924229351\n",
      "Число признаков: 68, AUC-ROC = 0.7353075234689483\n",
      "Число признаков: 69, AUC-ROC = 0.7353651638682429\n"
     ]
    }
   ],
   "source": [
    "for i in range(50, 70):\n",
    "    X_f_classif = SelectKBest(k = i).fit_transform(X_train_1, y_train)\n",
    "    scores = cross_val_score(GradientBoostingClassifier(),\n",
    "    X_f_classif, y_train, scoring = 'roc_auc', cv = skf, n_jobs = -1)\n",
    "    print(f'Число признаков: {i}, AUC-ROC =', scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Максимальное качество достигается при отборе 52 лучших признаков:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_f_classif = SelectKBest(k = 52).fit_transform(X_train_1, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. Подберите оптимальные параметры модели. Обратите внимание, что в зависимости от того, как вы обработали исходные данные, сделали ли балансировку классов, сколько объектов оставили в обучающей выборке и др. оптимальные значения параметров могут меняться. Возьмите наилучшее из ваших решений на текущий момент и проведите процедуру подбора параметров модели (обратите внимание на `sklearn.model_selection.GridSearchCV`) Как подбор параметров повлиял на качество модели?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры: {'learning_rate': 0.1, 'max_depth': 2}\n",
      "Лучшее качество: 0.7393115029195204\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {'max_depth' : [2, 3, 4, 5], 'learning_rate' : [0.05, 0.075, 0.1]}\n",
    "grid = GridSearchCV(GradientBoostingClassifier(), params, \n",
    "                    scoring = 'roc_auc', cv = skf)\n",
    "grid.fit(X_f_classif, y_train)\n",
    "print('Лучшие параметры:', grid.best_params_)\n",
    "print('Лучшее качество:', grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7\\. Предложите методику оценки того, какие признаки внесли наибольший вклад в модель (например, это могут быть веса в случае регрессии, а также большое количество моделей реализуют метод `feature_importances_` - оценка важности признаков). На основе предложенной методики проанализируйте, какие признаки внесли больший вклад в модель, а какие меньший?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>feature_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Var126</td>\n",
       "      <td>0.257542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>Var189</td>\n",
       "      <td>0.089351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>Var218</td>\n",
       "      <td>0.086937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Var113</td>\n",
       "      <td>0.073681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>Var192</td>\n",
       "      <td>0.053940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Var95</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Var96</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Var98</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Var99</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>Var229</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>212 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature  feature_importance\n",
       "114  Var126            0.257542\n",
       "172  Var189            0.089351\n",
       "200  Var218            0.086937\n",
       "101  Var113            0.073681\n",
       "175  Var192            0.053940\n",
       "..      ...                 ...\n",
       "83    Var95            0.000000\n",
       "84    Var96            0.000000\n",
       "86    Var98            0.000000\n",
       "87    Var99            0.000000\n",
       "211  Var229            0.000000\n",
       "\n",
       "[212 rows x 2 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(learning_rate = 0.1, max_depth = 2)\n",
    "clf.fit(X_train, y_train)\n",
    "features = pd.DataFrame({'feature' : X_train.columns, 'feature_importance' : clf.feature_importances_})\n",
    "features.sort_values('feature_importance', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Наибольший вклад в модель внесли признаки Var126, Var189, Var218, Var113, Var192, наименьший(0) - Var95, Var96, Var98, Var99, Var229."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8\\. Напоследок давайте посмотрим на объекты. На каких объектах достигается наибольшая ошибка классификации? Есть ли межу этими объектами что-то общее? Видны ли какие-либо закономерности? Предположите, почему наибольшая ошибка достигается именно на этих объектах. В данном случае \"наибольшую\" ошибку можно понимать как отнесение объекта с чужому классу с большой долей уверенности (с высокой вероятностью)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_train)\n",
    "probabilities = [x[1] for x in xgb_clf.predict_proba(X_train)]\n",
    "false_positives = X_train[np.array(np.logical_and(predictions == 1, y_train == -1))]\n",
    "false_negatives = X_train[np.array(np.logical_and(predictions == -1, y_train == 1))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True positives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var1</th>\n",
       "      <th>Var2</th>\n",
       "      <th>Var3</th>\n",
       "      <th>Var4</th>\n",
       "      <th>Var5</th>\n",
       "      <th>Var6</th>\n",
       "      <th>Var7</th>\n",
       "      <th>Var9</th>\n",
       "      <th>Var10</th>\n",
       "      <th>Var11</th>\n",
       "      <th>...</th>\n",
       "      <th>Var220</th>\n",
       "      <th>Var221</th>\n",
       "      <th>Var222</th>\n",
       "      <th>Var223</th>\n",
       "      <th>Var224</th>\n",
       "      <th>Var225</th>\n",
       "      <th>Var226</th>\n",
       "      <th>Var227</th>\n",
       "      <th>Var228</th>\n",
       "      <th>Var229</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.789272</td>\n",
       "      <td>0.010684</td>\n",
       "      <td>594.308351</td>\n",
       "      <td>0.079929</td>\n",
       "      <td>276425.49</td>\n",
       "      <td>1533.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>51.02682</td>\n",
       "      <td>364740.282</td>\n",
       "      <td>8.56531</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>13530</td>\n",
       "      <td>17</td>\n",
       "      <td>13391</td>\n",
       "      <td>17989</td>\n",
       "      <td>9571</td>\n",
       "      <td>747</td>\n",
       "      <td>12864</td>\n",
       "      <td>11993</td>\n",
       "      <td>10365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>10.789272</td>\n",
       "      <td>0.010684</td>\n",
       "      <td>594.308351</td>\n",
       "      <td>0.079929</td>\n",
       "      <td>276425.49</td>\n",
       "      <td>252.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.02682</td>\n",
       "      <td>364740.282</td>\n",
       "      <td>8.56531</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>13530</td>\n",
       "      <td>5</td>\n",
       "      <td>13391</td>\n",
       "      <td>17989</td>\n",
       "      <td>9571</td>\n",
       "      <td>482</td>\n",
       "      <td>12864</td>\n",
       "      <td>11993</td>\n",
       "      <td>10365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>10.789272</td>\n",
       "      <td>0.010684</td>\n",
       "      <td>594.308351</td>\n",
       "      <td>0.079929</td>\n",
       "      <td>276425.49</td>\n",
       "      <td>5859.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>51.02682</td>\n",
       "      <td>364740.282</td>\n",
       "      <td>8.56531</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>13530</td>\n",
       "      <td>13</td>\n",
       "      <td>13391</td>\n",
       "      <td>17989</td>\n",
       "      <td>9571</td>\n",
       "      <td>1112</td>\n",
       "      <td>12864</td>\n",
       "      <td>11993</td>\n",
       "      <td>10365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>10.789272</td>\n",
       "      <td>0.010684</td>\n",
       "      <td>594.308351</td>\n",
       "      <td>0.079929</td>\n",
       "      <td>276425.49</td>\n",
       "      <td>882.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>51.02682</td>\n",
       "      <td>364740.282</td>\n",
       "      <td>8.56531</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>13530</td>\n",
       "      <td>11</td>\n",
       "      <td>2196</td>\n",
       "      <td>17989</td>\n",
       "      <td>3795</td>\n",
       "      <td>790</td>\n",
       "      <td>12864</td>\n",
       "      <td>11993</td>\n",
       "      <td>3614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>10.789272</td>\n",
       "      <td>0.010684</td>\n",
       "      <td>594.308351</td>\n",
       "      <td>0.079929</td>\n",
       "      <td>276425.49</td>\n",
       "      <td>1078.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.02682</td>\n",
       "      <td>364740.282</td>\n",
       "      <td>8.56531</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>13530</td>\n",
       "      <td>22</td>\n",
       "      <td>13391</td>\n",
       "      <td>17989</td>\n",
       "      <td>9571</td>\n",
       "      <td>499</td>\n",
       "      <td>12864</td>\n",
       "      <td>11993</td>\n",
       "      <td>10365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18233</th>\n",
       "      <td>10.789272</td>\n",
       "      <td>0.010684</td>\n",
       "      <td>594.308351</td>\n",
       "      <td>0.079929</td>\n",
       "      <td>276425.49</td>\n",
       "      <td>679.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.02682</td>\n",
       "      <td>364740.282</td>\n",
       "      <td>8.56531</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>619</td>\n",
       "      <td>1</td>\n",
       "      <td>13391</td>\n",
       "      <td>17989</td>\n",
       "      <td>9571</td>\n",
       "      <td>2924</td>\n",
       "      <td>864</td>\n",
       "      <td>533</td>\n",
       "      <td>10365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18241</th>\n",
       "      <td>10.789272</td>\n",
       "      <td>0.010684</td>\n",
       "      <td>594.308351</td>\n",
       "      <td>0.079929</td>\n",
       "      <td>276425.49</td>\n",
       "      <td>819.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>51.02682</td>\n",
       "      <td>364740.282</td>\n",
       "      <td>8.56531</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>13530</td>\n",
       "      <td>3</td>\n",
       "      <td>2196</td>\n",
       "      <td>17989</td>\n",
       "      <td>3795</td>\n",
       "      <td>2924</td>\n",
       "      <td>12864</td>\n",
       "      <td>11993</td>\n",
       "      <td>4288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18291</th>\n",
       "      <td>10.789272</td>\n",
       "      <td>0.010684</td>\n",
       "      <td>594.308351</td>\n",
       "      <td>0.079929</td>\n",
       "      <td>276425.49</td>\n",
       "      <td>196.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.02682</td>\n",
       "      <td>364740.282</td>\n",
       "      <td>8.56531</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>13530</td>\n",
       "      <td>15</td>\n",
       "      <td>2196</td>\n",
       "      <td>17989</td>\n",
       "      <td>9571</td>\n",
       "      <td>2924</td>\n",
       "      <td>12864</td>\n",
       "      <td>11993</td>\n",
       "      <td>10365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18292</th>\n",
       "      <td>10.789272</td>\n",
       "      <td>0.010684</td>\n",
       "      <td>594.308351</td>\n",
       "      <td>0.079929</td>\n",
       "      <td>276425.49</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.02682</td>\n",
       "      <td>364740.282</td>\n",
       "      <td>8.56531</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>13530</td>\n",
       "      <td>31</td>\n",
       "      <td>13391</td>\n",
       "      <td>17989</td>\n",
       "      <td>9571</td>\n",
       "      <td>959</td>\n",
       "      <td>12864</td>\n",
       "      <td>11993</td>\n",
       "      <td>10365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18295</th>\n",
       "      <td>10.789272</td>\n",
       "      <td>0.010684</td>\n",
       "      <td>594.308351</td>\n",
       "      <td>0.079929</td>\n",
       "      <td>276425.49</td>\n",
       "      <td>1603.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>51.02682</td>\n",
       "      <td>364740.282</td>\n",
       "      <td>8.56531</td>\n",
       "      <td>...</td>\n",
       "      <td>1650</td>\n",
       "      <td>2269</td>\n",
       "      <td>1650</td>\n",
       "      <td>13391</td>\n",
       "      <td>17989</td>\n",
       "      <td>3795</td>\n",
       "      <td>467</td>\n",
       "      <td>2256</td>\n",
       "      <td>984</td>\n",
       "      <td>4288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1377 rows × 212 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Var1      Var2        Var3      Var4       Var5    Var6  Var7  \\\n",
       "ID                                                                          \n",
       "3      10.789272  0.010684  594.308351  0.079929  276425.49  1533.0   7.0   \n",
       "29     10.789272  0.010684  594.308351  0.079929  276425.49   252.0   0.0   \n",
       "49     10.789272  0.010684  594.308351  0.079929  276425.49  5859.0   7.0   \n",
       "68     10.789272  0.010684  594.308351  0.079929  276425.49   882.0   7.0   \n",
       "69     10.789272  0.010684  594.308351  0.079929  276425.49  1078.0   0.0   \n",
       "...          ...       ...         ...       ...        ...     ...   ...   \n",
       "18233  10.789272  0.010684  594.308351  0.079929  276425.49   679.0   0.0   \n",
       "18241  10.789272  0.010684  594.308351  0.079929  276425.49   819.0   7.0   \n",
       "18291  10.789272  0.010684  594.308351  0.079929  276425.49   196.0   0.0   \n",
       "18292  10.789272  0.010684  594.308351  0.079929  276425.49    77.0   0.0   \n",
       "18295  10.789272  0.010684  594.308351  0.079929  276425.49  1603.0   7.0   \n",
       "\n",
       "           Var9       Var10    Var11  ...  Var220  Var221  Var222  Var223  \\\n",
       "ID                                    ...                                   \n",
       "3      51.02682  364740.282  8.56531  ...      17   13530      17   13391   \n",
       "29     51.02682  364740.282  8.56531  ...       5   13530       5   13391   \n",
       "49     51.02682  364740.282  8.56531  ...      13   13530      13   13391   \n",
       "68     51.02682  364740.282  8.56531  ...      11   13530      11    2196   \n",
       "69     51.02682  364740.282  8.56531  ...      22   13530      22   13391   \n",
       "...         ...         ...      ...  ...     ...     ...     ...     ...   \n",
       "18233  51.02682  364740.282  8.56531  ...       1     619       1   13391   \n",
       "18241  51.02682  364740.282  8.56531  ...       3   13530       3    2196   \n",
       "18291  51.02682  364740.282  8.56531  ...      15   13530      15    2196   \n",
       "18292  51.02682  364740.282  8.56531  ...      31   13530      31   13391   \n",
       "18295  51.02682  364740.282  8.56531  ...    1650    2269    1650   13391   \n",
       "\n",
       "       Var224  Var225  Var226  Var227  Var228  Var229  \n",
       "ID                                                     \n",
       "3       17989    9571     747   12864   11993   10365  \n",
       "29      17989    9571     482   12864   11993   10365  \n",
       "49      17989    9571    1112   12864   11993   10365  \n",
       "68      17989    3795     790   12864   11993    3614  \n",
       "69      17989    9571     499   12864   11993   10365  \n",
       "...       ...     ...     ...     ...     ...     ...  \n",
       "18233   17989    9571    2924     864     533   10365  \n",
       "18241   17989    3795    2924   12864   11993    4288  \n",
       "18291   17989    9571    2924   12864   11993   10365  \n",
       "18292   17989    9571     959   12864   11993   10365  \n",
       "18295   17989    3795     467    2256     984    4288  \n",
       "\n",
       "[1377 rows x 212 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[np.array(y_train == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var1</th>\n",
       "      <th>Var2</th>\n",
       "      <th>Var3</th>\n",
       "      <th>Var4</th>\n",
       "      <th>Var5</th>\n",
       "      <th>Var6</th>\n",
       "      <th>Var7</th>\n",
       "      <th>Var9</th>\n",
       "      <th>Var10</th>\n",
       "      <th>Var11</th>\n",
       "      <th>...</th>\n",
       "      <th>Var220</th>\n",
       "      <th>Var221</th>\n",
       "      <th>Var222</th>\n",
       "      <th>Var223</th>\n",
       "      <th>Var224</th>\n",
       "      <th>Var225</th>\n",
       "      <th>Var226</th>\n",
       "      <th>Var227</th>\n",
       "      <th>Var228</th>\n",
       "      <th>Var229</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6984</th>\n",
       "      <td>10.789272</td>\n",
       "      <td>0.010684</td>\n",
       "      <td>594.308351</td>\n",
       "      <td>0.079929</td>\n",
       "      <td>276425.49</td>\n",
       "      <td>280.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.02682</td>\n",
       "      <td>364740.282</td>\n",
       "      <td>8.56531</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>13530</td>\n",
       "      <td>18</td>\n",
       "      <td>13391</td>\n",
       "      <td>17989</td>\n",
       "      <td>9571</td>\n",
       "      <td>2924</td>\n",
       "      <td>12864</td>\n",
       "      <td>11993</td>\n",
       "      <td>10365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9118</th>\n",
       "      <td>10.789272</td>\n",
       "      <td>0.010684</td>\n",
       "      <td>594.308351</td>\n",
       "      <td>0.079929</td>\n",
       "      <td>276425.49</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.02682</td>\n",
       "      <td>364740.282</td>\n",
       "      <td>8.56531</td>\n",
       "      <td>...</td>\n",
       "      <td>37</td>\n",
       "      <td>13530</td>\n",
       "      <td>37</td>\n",
       "      <td>13391</td>\n",
       "      <td>17989</td>\n",
       "      <td>9571</td>\n",
       "      <td>790</td>\n",
       "      <td>12864</td>\n",
       "      <td>11993</td>\n",
       "      <td>10365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9276</th>\n",
       "      <td>10.789272</td>\n",
       "      <td>0.010684</td>\n",
       "      <td>594.308351</td>\n",
       "      <td>0.079929</td>\n",
       "      <td>276425.49</td>\n",
       "      <td>574.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.02682</td>\n",
       "      <td>364740.282</td>\n",
       "      <td>8.56531</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>13530</td>\n",
       "      <td>14</td>\n",
       "      <td>13391</td>\n",
       "      <td>17989</td>\n",
       "      <td>9571</td>\n",
       "      <td>2924</td>\n",
       "      <td>12864</td>\n",
       "      <td>11993</td>\n",
       "      <td>10365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13404</th>\n",
       "      <td>10.789272</td>\n",
       "      <td>0.010684</td>\n",
       "      <td>594.308351</td>\n",
       "      <td>0.079929</td>\n",
       "      <td>276425.49</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.02682</td>\n",
       "      <td>364740.282</td>\n",
       "      <td>8.56531</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>13530</td>\n",
       "      <td>30</td>\n",
       "      <td>13391</td>\n",
       "      <td>17989</td>\n",
       "      <td>9571</td>\n",
       "      <td>959</td>\n",
       "      <td>12864</td>\n",
       "      <td>11993</td>\n",
       "      <td>10365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14627</th>\n",
       "      <td>10.789272</td>\n",
       "      <td>0.010684</td>\n",
       "      <td>594.308351</td>\n",
       "      <td>0.079929</td>\n",
       "      <td>276425.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.02682</td>\n",
       "      <td>364740.282</td>\n",
       "      <td>8.56531</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>13530</td>\n",
       "      <td>5</td>\n",
       "      <td>1882</td>\n",
       "      <td>17989</td>\n",
       "      <td>9571</td>\n",
       "      <td>2924</td>\n",
       "      <td>12864</td>\n",
       "      <td>11993</td>\n",
       "      <td>10365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17110</th>\n",
       "      <td>10.789272</td>\n",
       "      <td>0.010684</td>\n",
       "      <td>594.308351</td>\n",
       "      <td>0.079929</td>\n",
       "      <td>276425.49</td>\n",
       "      <td>623.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.02682</td>\n",
       "      <td>364740.282</td>\n",
       "      <td>8.56531</td>\n",
       "      <td>...</td>\n",
       "      <td>37</td>\n",
       "      <td>13530</td>\n",
       "      <td>37</td>\n",
       "      <td>13391</td>\n",
       "      <td>17989</td>\n",
       "      <td>9571</td>\n",
       "      <td>1828</td>\n",
       "      <td>2256</td>\n",
       "      <td>298</td>\n",
       "      <td>10365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17147</th>\n",
       "      <td>10.789272</td>\n",
       "      <td>0.010684</td>\n",
       "      <td>594.308351</td>\n",
       "      <td>0.079929</td>\n",
       "      <td>276425.49</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.02682</td>\n",
       "      <td>364740.282</td>\n",
       "      <td>8.56531</td>\n",
       "      <td>...</td>\n",
       "      <td>33</td>\n",
       "      <td>13530</td>\n",
       "      <td>33</td>\n",
       "      <td>13391</td>\n",
       "      <td>17989</td>\n",
       "      <td>9571</td>\n",
       "      <td>482</td>\n",
       "      <td>12864</td>\n",
       "      <td>11993</td>\n",
       "      <td>10365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 212 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Var1      Var2        Var3      Var4       Var5   Var6  Var7  \\\n",
       "ID                                                                         \n",
       "6984   10.789272  0.010684  594.308351  0.079929  276425.49  280.0   0.0   \n",
       "9118   10.789272  0.010684  594.308351  0.079929  276425.49  175.0   0.0   \n",
       "9276   10.789272  0.010684  594.308351  0.079929  276425.49  574.0   0.0   \n",
       "13404  10.789272  0.010684  594.308351  0.079929  276425.49   77.0   0.0   \n",
       "14627  10.789272  0.010684  594.308351  0.079929  276425.49    0.0   0.0   \n",
       "17110  10.789272  0.010684  594.308351  0.079929  276425.49  623.0   0.0   \n",
       "17147  10.789272  0.010684  594.308351  0.079929  276425.49   42.0   0.0   \n",
       "\n",
       "           Var9       Var10    Var11  ...  Var220  Var221  Var222  Var223  \\\n",
       "ID                                    ...                                   \n",
       "6984   51.02682  364740.282  8.56531  ...      18   13530      18   13391   \n",
       "9118   51.02682  364740.282  8.56531  ...      37   13530      37   13391   \n",
       "9276   51.02682  364740.282  8.56531  ...      14   13530      14   13391   \n",
       "13404  51.02682  364740.282  8.56531  ...      30   13530      30   13391   \n",
       "14627  51.02682  364740.282  8.56531  ...       5   13530       5    1882   \n",
       "17110  51.02682  364740.282  8.56531  ...      37   13530      37   13391   \n",
       "17147  51.02682  364740.282  8.56531  ...      33   13530      33   13391   \n",
       "\n",
       "       Var224  Var225  Var226  Var227  Var228  Var229  \n",
       "ID                                                     \n",
       "6984    17989    9571    2924   12864   11993   10365  \n",
       "9118    17989    9571     790   12864   11993   10365  \n",
       "9276    17989    9571    2924   12864   11993   10365  \n",
       "13404   17989    9571     959   12864   11993   10365  \n",
       "14627   17989    9571    2924   12864   11993   10365  \n",
       "17110   17989    9571    1828    2256     298   10365  \n",
       "17147   17989    9571     482   12864   11993   10365  \n",
       "\n",
       "[7 rows x 212 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_positives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True negatives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var1</th>\n",
       "      <th>Var2</th>\n",
       "      <th>Var3</th>\n",
       "      <th>Var4</th>\n",
       "      <th>Var5</th>\n",
       "      <th>Var6</th>\n",
       "      <th>Var7</th>\n",
       "      <th>Var9</th>\n",
       "      <th>Var10</th>\n",
       "      <th>Var11</th>\n",
       "      <th>...</th>\n",
       "      <th>Var220</th>\n",
       "      <th>Var221</th>\n",
       "      <th>Var222</th>\n",
       "      <th>Var223</th>\n",
       "      <th>Var224</th>\n",
       "      <th>Var225</th>\n",
       "      <th>Var226</th>\n",
       "      <th>Var227</th>\n",
       "      <th>Var228</th>\n",
       "      <th>Var229</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.789272</td>\n",
       "      <td>0.010684</td>\n",
       "      <td>594.308351</td>\n",
       "      <td>0.079929</td>\n",
       "      <td>276425.49</td>\n",
       "      <td>3052.000000</td>\n",
       "      <td>6.790725</td>\n",
       "      <td>51.02682</td>\n",
       "      <td>364740.282</td>\n",
       "      <td>8.56531</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>619</td>\n",
       "      <td>1</td>\n",
       "      <td>13391</td>\n",
       "      <td>17989</td>\n",
       "      <td>9571</td>\n",
       "      <td>959</td>\n",
       "      <td>864</td>\n",
       "      <td>533</td>\n",
       "      <td>10365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.789272</td>\n",
       "      <td>0.010684</td>\n",
       "      <td>594.308351</td>\n",
       "      <td>0.079929</td>\n",
       "      <td>276425.49</td>\n",
       "      <td>1813.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>51.02682</td>\n",
       "      <td>364740.282</td>\n",
       "      <td>8.56531</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>13530</td>\n",
       "      <td>1</td>\n",
       "      <td>13391</td>\n",
       "      <td>17989</td>\n",
       "      <td>4088</td>\n",
       "      <td>747</td>\n",
       "      <td>12864</td>\n",
       "      <td>1570</td>\n",
       "      <td>3614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.789272</td>\n",
       "      <td>0.010684</td>\n",
       "      <td>594.308351</td>\n",
       "      <td>0.079929</td>\n",
       "      <td>276425.49</td>\n",
       "      <td>1953.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>51.02682</td>\n",
       "      <td>364740.282</td>\n",
       "      <td>8.56531</td>\n",
       "      <td>...</td>\n",
       "      <td>1650</td>\n",
       "      <td>2269</td>\n",
       "      <td>1650</td>\n",
       "      <td>13391</td>\n",
       "      <td>17989</td>\n",
       "      <td>9571</td>\n",
       "      <td>2924</td>\n",
       "      <td>2256</td>\n",
       "      <td>984</td>\n",
       "      <td>3614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.789272</td>\n",
       "      <td>0.010684</td>\n",
       "      <td>594.308351</td>\n",
       "      <td>0.079929</td>\n",
       "      <td>276425.49</td>\n",
       "      <td>686.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>51.02682</td>\n",
       "      <td>364740.282</td>\n",
       "      <td>8.56531</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>13530</td>\n",
       "      <td>2</td>\n",
       "      <td>13391</td>\n",
       "      <td>17989</td>\n",
       "      <td>9571</td>\n",
       "      <td>1590</td>\n",
       "      <td>12864</td>\n",
       "      <td>11993</td>\n",
       "      <td>10365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010684</td>\n",
       "      <td>594.308351</td>\n",
       "      <td>0.079929</td>\n",
       "      <td>276425.49</td>\n",
       "      <td>1304.000245</td>\n",
       "      <td>6.790725</td>\n",
       "      <td>30.00000</td>\n",
       "      <td>364740.282</td>\n",
       "      <td>8.56531</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1151</td>\n",
       "      <td>1</td>\n",
       "      <td>13391</td>\n",
       "      <td>17989</td>\n",
       "      <td>9571</td>\n",
       "      <td>790</td>\n",
       "      <td>864</td>\n",
       "      <td>11993</td>\n",
       "      <td>10365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18290</th>\n",
       "      <td>10.789272</td>\n",
       "      <td>0.010684</td>\n",
       "      <td>594.308351</td>\n",
       "      <td>0.079929</td>\n",
       "      <td>236575.00</td>\n",
       "      <td>1304.000245</td>\n",
       "      <td>6.790725</td>\n",
       "      <td>51.02682</td>\n",
       "      <td>1326897.000</td>\n",
       "      <td>8.56531</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>13530</td>\n",
       "      <td>15</td>\n",
       "      <td>13391</td>\n",
       "      <td>17989</td>\n",
       "      <td>9571</td>\n",
       "      <td>965</td>\n",
       "      <td>12864</td>\n",
       "      <td>11993</td>\n",
       "      <td>10365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18293</th>\n",
       "      <td>10.789272</td>\n",
       "      <td>0.010684</td>\n",
       "      <td>594.308351</td>\n",
       "      <td>0.079929</td>\n",
       "      <td>276425.49</td>\n",
       "      <td>3892.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51.02682</td>\n",
       "      <td>364740.282</td>\n",
       "      <td>8.56531</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>13530</td>\n",
       "      <td>16</td>\n",
       "      <td>1882</td>\n",
       "      <td>17989</td>\n",
       "      <td>9571</td>\n",
       "      <td>526</td>\n",
       "      <td>12864</td>\n",
       "      <td>11993</td>\n",
       "      <td>10365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18294</th>\n",
       "      <td>10.789272</td>\n",
       "      <td>0.010684</td>\n",
       "      <td>594.308351</td>\n",
       "      <td>0.079929</td>\n",
       "      <td>276425.49</td>\n",
       "      <td>462.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51.02682</td>\n",
       "      <td>364740.282</td>\n",
       "      <td>8.56531</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>13530</td>\n",
       "      <td>16</td>\n",
       "      <td>13391</td>\n",
       "      <td>17989</td>\n",
       "      <td>9571</td>\n",
       "      <td>467</td>\n",
       "      <td>12864</td>\n",
       "      <td>11993</td>\n",
       "      <td>10365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18296</th>\n",
       "      <td>10.789272</td>\n",
       "      <td>0.010684</td>\n",
       "      <td>594.308351</td>\n",
       "      <td>0.079929</td>\n",
       "      <td>276425.49</td>\n",
       "      <td>1239.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>51.02682</td>\n",
       "      <td>364740.282</td>\n",
       "      <td>8.56531</td>\n",
       "      <td>...</td>\n",
       "      <td>1650</td>\n",
       "      <td>13530</td>\n",
       "      <td>1650</td>\n",
       "      <td>13391</td>\n",
       "      <td>17989</td>\n",
       "      <td>4088</td>\n",
       "      <td>749</td>\n",
       "      <td>2256</td>\n",
       "      <td>1570</td>\n",
       "      <td>4288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18297</th>\n",
       "      <td>10.789272</td>\n",
       "      <td>0.010684</td>\n",
       "      <td>594.308351</td>\n",
       "      <td>0.079929</td>\n",
       "      <td>276425.49</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51.02682</td>\n",
       "      <td>364740.282</td>\n",
       "      <td>8.56531</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>13530</td>\n",
       "      <td>15</td>\n",
       "      <td>13391</td>\n",
       "      <td>17989</td>\n",
       "      <td>9571</td>\n",
       "      <td>1590</td>\n",
       "      <td>12864</td>\n",
       "      <td>11993</td>\n",
       "      <td>10365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16921 rows × 212 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Var1      Var2        Var3      Var4       Var5         Var6  \\\n",
       "ID                                                                         \n",
       "0      10.789272  0.010684  594.308351  0.079929  276425.49  3052.000000   \n",
       "1      10.789272  0.010684  594.308351  0.079929  276425.49  1813.000000   \n",
       "2      10.789272  0.010684  594.308351  0.079929  276425.49  1953.000000   \n",
       "4      10.789272  0.010684  594.308351  0.079929  276425.49   686.000000   \n",
       "5       0.000000  0.010684  594.308351  0.079929  276425.49  1304.000245   \n",
       "...          ...       ...         ...       ...        ...          ...   \n",
       "18290  10.789272  0.010684  594.308351  0.079929  236575.00  1304.000245   \n",
       "18293  10.789272  0.010684  594.308351  0.079929  276425.49  3892.000000   \n",
       "18294  10.789272  0.010684  594.308351  0.079929  276425.49   462.000000   \n",
       "18296  10.789272  0.010684  594.308351  0.079929  276425.49  1239.000000   \n",
       "18297  10.789272  0.010684  594.308351  0.079929  276425.49   210.000000   \n",
       "\n",
       "           Var7      Var9        Var10    Var11  ...  Var220  Var221  Var222  \\\n",
       "ID                                               ...                           \n",
       "0      6.790725  51.02682   364740.282  8.56531  ...       1     619       1   \n",
       "1      7.000000  51.02682   364740.282  8.56531  ...       1   13530       1   \n",
       "2      7.000000  51.02682   364740.282  8.56531  ...    1650    2269    1650   \n",
       "4      7.000000  51.02682   364740.282  8.56531  ...       2   13530       2   \n",
       "5      6.790725  30.00000   364740.282  8.56531  ...       1    1151       1   \n",
       "...         ...       ...          ...      ...  ...     ...     ...     ...   \n",
       "18290  6.790725  51.02682  1326897.000  8.56531  ...      15   13530      15   \n",
       "18293  0.000000  51.02682   364740.282  8.56531  ...      16   13530      16   \n",
       "18294  0.000000  51.02682   364740.282  8.56531  ...      16   13530      16   \n",
       "18296  7.000000  51.02682   364740.282  8.56531  ...    1650   13530    1650   \n",
       "18297  0.000000  51.02682   364740.282  8.56531  ...      15   13530      15   \n",
       "\n",
       "       Var223  Var224  Var225  Var226  Var227  Var228  Var229  \n",
       "ID                                                             \n",
       "0       13391   17989    9571     959     864     533   10365  \n",
       "1       13391   17989    4088     747   12864    1570    3614  \n",
       "2       13391   17989    9571    2924    2256     984    3614  \n",
       "4       13391   17989    9571    1590   12864   11993   10365  \n",
       "5       13391   17989    9571     790     864   11993   10365  \n",
       "...       ...     ...     ...     ...     ...     ...     ...  \n",
       "18290   13391   17989    9571     965   12864   11993   10365  \n",
       "18293    1882   17989    9571     526   12864   11993   10365  \n",
       "18294   13391   17989    9571     467   12864   11993   10365  \n",
       "18296   13391   17989    4088     749    2256    1570    4288  \n",
       "18297   13391   17989    9571    1590   12864   11993   10365  \n",
       "\n",
       "[16921 rows x 212 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[np.array(y_train == -1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var1</th>\n",
       "      <th>Var2</th>\n",
       "      <th>Var3</th>\n",
       "      <th>Var4</th>\n",
       "      <th>Var5</th>\n",
       "      <th>Var6</th>\n",
       "      <th>Var7</th>\n",
       "      <th>Var9</th>\n",
       "      <th>Var10</th>\n",
       "      <th>Var11</th>\n",
       "      <th>...</th>\n",
       "      <th>Var220</th>\n",
       "      <th>Var221</th>\n",
       "      <th>Var222</th>\n",
       "      <th>Var223</th>\n",
       "      <th>Var224</th>\n",
       "      <th>Var225</th>\n",
       "      <th>Var226</th>\n",
       "      <th>Var227</th>\n",
       "      <th>Var228</th>\n",
       "      <th>Var229</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.789272</td>\n",
       "      <td>0.010684</td>\n",
       "      <td>594.308351</td>\n",
       "      <td>0.079929</td>\n",
       "      <td>276425.49</td>\n",
       "      <td>1533.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>51.02682</td>\n",
       "      <td>364740.282</td>\n",
       "      <td>8.56531</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>13530</td>\n",
       "      <td>17</td>\n",
       "      <td>13391</td>\n",
       "      <td>17989</td>\n",
       "      <td>9571</td>\n",
       "      <td>747</td>\n",
       "      <td>12864</td>\n",
       "      <td>11993</td>\n",
       "      <td>10365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>10.789272</td>\n",
       "      <td>0.010684</td>\n",
       "      <td>594.308351</td>\n",
       "      <td>0.079929</td>\n",
       "      <td>276425.49</td>\n",
       "      <td>252.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.02682</td>\n",
       "      <td>364740.282</td>\n",
       "      <td>8.56531</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>13530</td>\n",
       "      <td>5</td>\n",
       "      <td>13391</td>\n",
       "      <td>17989</td>\n",
       "      <td>9571</td>\n",
       "      <td>482</td>\n",
       "      <td>12864</td>\n",
       "      <td>11993</td>\n",
       "      <td>10365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>10.789272</td>\n",
       "      <td>0.010684</td>\n",
       "      <td>594.308351</td>\n",
       "      <td>0.079929</td>\n",
       "      <td>276425.49</td>\n",
       "      <td>882.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>51.02682</td>\n",
       "      <td>364740.282</td>\n",
       "      <td>8.56531</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>13530</td>\n",
       "      <td>11</td>\n",
       "      <td>2196</td>\n",
       "      <td>17989</td>\n",
       "      <td>3795</td>\n",
       "      <td>790</td>\n",
       "      <td>12864</td>\n",
       "      <td>11993</td>\n",
       "      <td>3614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>10.789272</td>\n",
       "      <td>0.010684</td>\n",
       "      <td>594.308351</td>\n",
       "      <td>0.079929</td>\n",
       "      <td>276425.49</td>\n",
       "      <td>1078.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.02682</td>\n",
       "      <td>364740.282</td>\n",
       "      <td>8.56531</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>13530</td>\n",
       "      <td>22</td>\n",
       "      <td>13391</td>\n",
       "      <td>17989</td>\n",
       "      <td>9571</td>\n",
       "      <td>499</td>\n",
       "      <td>12864</td>\n",
       "      <td>11993</td>\n",
       "      <td>10365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>10.789272</td>\n",
       "      <td>0.010684</td>\n",
       "      <td>594.308351</td>\n",
       "      <td>0.079929</td>\n",
       "      <td>276425.49</td>\n",
       "      <td>154.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.02682</td>\n",
       "      <td>364740.282</td>\n",
       "      <td>8.56531</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>13530</td>\n",
       "      <td>22</td>\n",
       "      <td>13391</td>\n",
       "      <td>17989</td>\n",
       "      <td>9571</td>\n",
       "      <td>2924</td>\n",
       "      <td>12864</td>\n",
       "      <td>11993</td>\n",
       "      <td>10365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18233</th>\n",
       "      <td>10.789272</td>\n",
       "      <td>0.010684</td>\n",
       "      <td>594.308351</td>\n",
       "      <td>0.079929</td>\n",
       "      <td>276425.49</td>\n",
       "      <td>679.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.02682</td>\n",
       "      <td>364740.282</td>\n",
       "      <td>8.56531</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>619</td>\n",
       "      <td>1</td>\n",
       "      <td>13391</td>\n",
       "      <td>17989</td>\n",
       "      <td>9571</td>\n",
       "      <td>2924</td>\n",
       "      <td>864</td>\n",
       "      <td>533</td>\n",
       "      <td>10365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18241</th>\n",
       "      <td>10.789272</td>\n",
       "      <td>0.010684</td>\n",
       "      <td>594.308351</td>\n",
       "      <td>0.079929</td>\n",
       "      <td>276425.49</td>\n",
       "      <td>819.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>51.02682</td>\n",
       "      <td>364740.282</td>\n",
       "      <td>8.56531</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>13530</td>\n",
       "      <td>3</td>\n",
       "      <td>2196</td>\n",
       "      <td>17989</td>\n",
       "      <td>3795</td>\n",
       "      <td>2924</td>\n",
       "      <td>12864</td>\n",
       "      <td>11993</td>\n",
       "      <td>4288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18291</th>\n",
       "      <td>10.789272</td>\n",
       "      <td>0.010684</td>\n",
       "      <td>594.308351</td>\n",
       "      <td>0.079929</td>\n",
       "      <td>276425.49</td>\n",
       "      <td>196.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.02682</td>\n",
       "      <td>364740.282</td>\n",
       "      <td>8.56531</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>13530</td>\n",
       "      <td>15</td>\n",
       "      <td>2196</td>\n",
       "      <td>17989</td>\n",
       "      <td>9571</td>\n",
       "      <td>2924</td>\n",
       "      <td>12864</td>\n",
       "      <td>11993</td>\n",
       "      <td>10365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18292</th>\n",
       "      <td>10.789272</td>\n",
       "      <td>0.010684</td>\n",
       "      <td>594.308351</td>\n",
       "      <td>0.079929</td>\n",
       "      <td>276425.49</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.02682</td>\n",
       "      <td>364740.282</td>\n",
       "      <td>8.56531</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>13530</td>\n",
       "      <td>31</td>\n",
       "      <td>13391</td>\n",
       "      <td>17989</td>\n",
       "      <td>9571</td>\n",
       "      <td>959</td>\n",
       "      <td>12864</td>\n",
       "      <td>11993</td>\n",
       "      <td>10365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18295</th>\n",
       "      <td>10.789272</td>\n",
       "      <td>0.010684</td>\n",
       "      <td>594.308351</td>\n",
       "      <td>0.079929</td>\n",
       "      <td>276425.49</td>\n",
       "      <td>1603.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>51.02682</td>\n",
       "      <td>364740.282</td>\n",
       "      <td>8.56531</td>\n",
       "      <td>...</td>\n",
       "      <td>1650</td>\n",
       "      <td>2269</td>\n",
       "      <td>1650</td>\n",
       "      <td>13391</td>\n",
       "      <td>17989</td>\n",
       "      <td>3795</td>\n",
       "      <td>467</td>\n",
       "      <td>2256</td>\n",
       "      <td>984</td>\n",
       "      <td>4288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1293 rows × 212 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Var1      Var2        Var3      Var4       Var5    Var6  Var7  \\\n",
       "ID                                                                          \n",
       "3      10.789272  0.010684  594.308351  0.079929  276425.49  1533.0   7.0   \n",
       "29     10.789272  0.010684  594.308351  0.079929  276425.49   252.0   0.0   \n",
       "68     10.789272  0.010684  594.308351  0.079929  276425.49   882.0   7.0   \n",
       "69     10.789272  0.010684  594.308351  0.079929  276425.49  1078.0   0.0   \n",
       "71     10.789272  0.010684  594.308351  0.079929  276425.49   154.0   0.0   \n",
       "...          ...       ...         ...       ...        ...     ...   ...   \n",
       "18233  10.789272  0.010684  594.308351  0.079929  276425.49   679.0   0.0   \n",
       "18241  10.789272  0.010684  594.308351  0.079929  276425.49   819.0   7.0   \n",
       "18291  10.789272  0.010684  594.308351  0.079929  276425.49   196.0   0.0   \n",
       "18292  10.789272  0.010684  594.308351  0.079929  276425.49    77.0   0.0   \n",
       "18295  10.789272  0.010684  594.308351  0.079929  276425.49  1603.0   7.0   \n",
       "\n",
       "           Var9       Var10    Var11  ...  Var220  Var221  Var222  Var223  \\\n",
       "ID                                    ...                                   \n",
       "3      51.02682  364740.282  8.56531  ...      17   13530      17   13391   \n",
       "29     51.02682  364740.282  8.56531  ...       5   13530       5   13391   \n",
       "68     51.02682  364740.282  8.56531  ...      11   13530      11    2196   \n",
       "69     51.02682  364740.282  8.56531  ...      22   13530      22   13391   \n",
       "71     51.02682  364740.282  8.56531  ...      22   13530      22   13391   \n",
       "...         ...         ...      ...  ...     ...     ...     ...     ...   \n",
       "18233  51.02682  364740.282  8.56531  ...       1     619       1   13391   \n",
       "18241  51.02682  364740.282  8.56531  ...       3   13530       3    2196   \n",
       "18291  51.02682  364740.282  8.56531  ...      15   13530      15    2196   \n",
       "18292  51.02682  364740.282  8.56531  ...      31   13530      31   13391   \n",
       "18295  51.02682  364740.282  8.56531  ...    1650    2269    1650   13391   \n",
       "\n",
       "       Var224  Var225  Var226  Var227  Var228  Var229  \n",
       "ID                                                     \n",
       "3       17989    9571     747   12864   11993   10365  \n",
       "29      17989    9571     482   12864   11993   10365  \n",
       "68      17989    3795     790   12864   11993    3614  \n",
       "69      17989    9571     499   12864   11993   10365  \n",
       "71      17989    9571    2924   12864   11993   10365  \n",
       "...       ...     ...     ...     ...     ...     ...  \n",
       "18233   17989    9571    2924     864     533   10365  \n",
       "18241   17989    3795    2924   12864   11993    4288  \n",
       "18291   17989    9571    2924   12864   11993   10365  \n",
       "18292   17989    9571     959   12864   11993   10365  \n",
       "18295   17989    3795     467    2256     984    4288  \n",
       "\n",
       "[1293 rows x 212 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Причина ошибок - сходство объектов false_positives с объектами класса 1 и объектов false_negatives c объектами класса -1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9\\. По итогам проведенных экспериментов постройте финальную решение - модель с наилучшим качеством. Укажите, какие преобразования данных, параметры и пр. вы выбрали для построения финальной модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(max_depth=2)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(learning_rate = 0.1, max_depth = 2)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполнено удаление пустых признаков, заполнение пропущенных значений числовых признаков средними по столбцам, отбор категориальных признаков с менее чем 100 значениями и кодирование их частотами значений признака в каждом столбце, отбор оптимального количества лучших признаков методом ANOVA F-value. Подобраны оптимальные параметры learning_rate и max_depth для градиентного бустинга."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10\\. Подумайте, можно ли еще улучшить модель? Что для этого можно сделать? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Для улучшения модели можно добавить новые переменные - индикаторы того, пропущено значение или нет, отмасштабировать числовые признаки. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
